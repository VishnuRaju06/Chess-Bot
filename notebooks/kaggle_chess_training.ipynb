{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kaggle Chess Policy Network Training Notebook\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "\n",
        "import chess\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Dataset paths (adapt as needed outside Kaggle)\n",
        "BASE_PATH = \"/kaggle/input/chess-dataset-splitted/Chess-dataset\"\n",
        "\n",
        "train_df = pl.read_parquet(f\"{BASE_PATH}/train_2450_2550.parquet\")\n",
        "val_df   = pl.read_parquet(f\"{BASE_PATH}/val_2450_2550.parquet\")\n",
        "test_df  = pl.read_parquet(f\"{BASE_PATH}/test_2450_2550.parquet\")\n",
        "\n",
        "print(\"Train/Val/Test shapes:\", train_df.shape, val_df.shape, test_df.shape)\n",
        "\n",
        "PIECE_TO_PLANE = {\n",
        "    chess.PAWN: 0, chess.KNIGHT: 1, chess.BISHOP: 2,\n",
        "    chess.ROOK: 3, chess.QUEEN: 4, chess.KING: 5,\n",
        "}\n",
        "\n",
        "\n",
        "def board_to_tensor(board: chess.Board):\n",
        "    tensor = np.zeros((18, 8, 8), dtype=np.float32)\n",
        "\n",
        "    for piece_type in PIECE_TO_PLANE:\n",
        "        for square in board.pieces(piece_type, chess.WHITE):\n",
        "            r, c = divmod(square, 8)\n",
        "            tensor[PIECE_TO_PLANE[piece_type], r, c] = 1\n",
        "\n",
        "        for square in board.pieces(piece_type, chess.BLACK):\n",
        "            r, c = divmod(square, 8)\n",
        "            tensor[PIECE_TO_PLANE[piece_type] + 6, r, c] = 1\n",
        "\n",
        "    tensor[12, :, :] = int(board.turn)\n",
        "    tensor[13, :, :] = board.has_kingside_castling_rights(chess.WHITE)\n",
        "    tensor[14, :, :] = board.has_queenside_castling_rights(chess.WHITE)\n",
        "    tensor[15, :, :] = board.has_kingside_castling_rights(chess.BLACK)\n",
        "    tensor[16, :, :] = board.has_queenside_castling_rights(chess.BLACK)\n",
        "\n",
        "    tensor[17, :, :] = board.fullmove_number / 100.0\n",
        "    return tensor\n",
        "\n",
        "\n",
        "def move_to_index(move: chess.Move):\n",
        "    return move.from_square * 64 + move.to_square\n",
        "\n",
        "\n",
        "class ChessPositionDataset(Dataset):\n",
        "    def __init__(self, df: pl.DataFrame):\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df.height\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.row(idx)\n",
        "\n",
        "        moves = row[self.df.columns.index(\"moves_uci\")]\n",
        "        if moves is None or len(moves) < 2:\n",
        "            return self.__getitem__((idx + 1) % len(self))\n",
        "\n",
        "        ply_idx = random.randint(0, len(moves) - 2)\n",
        "\n",
        "        board = chess.Board()\n",
        "        for i in range(ply_idx):\n",
        "            board.push_uci(moves[i])\n",
        "\n",
        "        x = board_to_tensor(board)\n",
        "        target_move = chess.Move.from_uci(moves[ply_idx])\n",
        "        y = move_to_index(target_move)\n",
        "\n",
        "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        return torch.relu(out + x)\n",
        "\n",
        "\n",
        "class ChessPolicyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(18, 256, 3, padding=1)\n",
        "        self.bn = nn.BatchNorm2d(256)\n",
        "        self.res_blocks = nn.Sequential(*[ResidualBlock(256) for _ in range(10)])\n",
        "        self.policy = nn.Conv2d(256, 73, 1)\n",
        "        self.fc = nn.Linear(73 * 8 * 8, 4672)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.bn(self.conv(x)))\n",
        "        x = self.res_blocks(x)\n",
        "        x = self.policy(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ChessPolicyNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "print(\"Model on device:\", device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DataLoaders\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    ChessPositionDataset(train_df),\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    ChessPositionDataset(val_df),\n",
        "    batch_size=128,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    ChessPositionDataset(test_df),\n",
        "    batch_size=128,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration and resume logic\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "\n",
        "# Paths (adapt if needed)\n",
        "INPUT_BEST_MODEL = \"/kaggle/input/chess-model/pytorch/default/1/best_model.pth\"\n",
        "OUTPUT_DIR = \"/kaggle/working\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "OUTPUT_BEST_MODEL = f\"{OUTPUT_DIR}/best_model.pth\"\n",
        "CHECKPOINT_PATH = f\"{OUTPUT_DIR}/checkpoint_latest.pth\"\n",
        "METRICS_PATH = f\"{OUTPUT_DIR}/metrics_history.pt\"\n",
        "\n",
        "EPOCHS = 100\n",
        "PATIENCE = 5\n",
        "MIN_DELTA = 1e-4\n",
        "\n",
        "# Load baseline best model\n",
        "model.load_state_dict(torch.load(INPUT_BEST_MODEL, map_location=device))\n",
        "model.to(device)\n",
        "print(\"Loaded baseline best model from Kaggle INPUT\")\n",
        "\n",
        "start_epoch = 0\n",
        "best_val_loss = float(\"inf\")\n",
        "early_stop_counter = 0\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode=\"min\",\n",
        "    factor=0.5,\n",
        "    patience=2,\n",
        ")\n",
        "\n",
        "if os.path.exists(METRICS_PATH):\n",
        "    metrics = torch.load(METRICS_PATH)\n",
        "else:\n",
        "    metrics = {\n",
        "        \"epochs\": [],\n",
        "        \"train_loss\": [],\n",
        "        \"val_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"val_acc\": [],\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Main training loop\n",
        "\n",
        "for epoch in range(start_epoch, EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
        "\n",
        "    # ----- TRAIN -----\n",
        "    model.train()\n",
        "    train_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * x.size(0)\n",
        "        correct += (logits.argmax(1) == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    train_loss /= total\n",
        "    train_acc = correct / total\n",
        "\n",
        "    # ----- VALIDATION -----\n",
        "    model.eval()\n",
        "    val_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "\n",
        "            val_loss += loss.item() * x.size(0)\n",
        "            correct += (logits.argmax(1) == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    val_loss /= total\n",
        "    val_acc = correct / total\n",
        "\n",
        "    # ----- METRICS -----\n",
        "    metrics[\"epochs\"].append(epoch)\n",
        "    metrics[\"train_loss\"].append(train_loss)\n",
        "    metrics[\"val_loss\"].append(val_loss)\n",
        "    metrics[\"train_acc\"].append(train_acc)\n",
        "    metrics[\"val_acc\"].append(val_acc)\n",
        "\n",
        "    torch.save(metrics, METRICS_PATH)\n",
        "\n",
        "    print(\n",
        "        f\"Train Loss {train_loss:.4f} | Train Acc {train_acc:.4f} | \"\n",
        "        f\"Val Loss {val_loss:.4f} | Val Acc {val_acc:.4f}\"\n",
        "    )\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # ----- CHECKPOINT -----\n",
        "    torch.save(\n",
        "        {\n",
        "            \"epoch\": epoch,\n",
        "            \"model\": model.state_dict(),\n",
        "            \"optimizer\": optimizer.state_dict(),\n",
        "            \"best_val_loss\": best_val_loss,\n",
        "        },\n",
        "        CHECKPOINT_PATH,\n",
        "    )\n",
        "\n",
        "    # ----- SAVE NEW BEST MODEL -----\n",
        "    if best_val_loss - val_loss > MIN_DELTA:\n",
        "        best_val_loss = val_loss\n",
        "        early_stop_counter = 0\n",
        "\n",
        "        torch.save(model.state_dict(), OUTPUT_BEST_MODEL)\n",
        "        print(\"✅ NEW BEST MODEL saved to /kaggle/working\")\n",
        "    else:\n",
        "        early_stop_counter += 1\n",
        "        print(f\"No improvement ({early_stop_counter}/{PATIENCE})\")\n",
        "\n",
        "    if early_stop_counter >= PATIENCE:\n",
        "        print(\"⛔ Early stopping triggered\")\n",
        "        break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot loss and accuracy curves\n",
        "\n",
        "metrics = torch.load(METRICS_PATH)\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(metrics[\"epochs\"], metrics[\"train_loss\"], label=\"Train Loss\")\n",
        "plt.plot(metrics[\"epochs\"], metrics[\"val_loss\"], label=\"Val Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Curve\")\n",
        "plt.legend()\n",
        "\n",
        "# Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(metrics[\"epochs\"], metrics[\"train_acc\"], label=\"Train Acc\")\n",
        "plt.plot(metrics[\"epochs\"], metrics[\"val_acc\"], label=\"Val Acc\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy Curve\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reload best model and define inference helpers\n",
        "\n",
        "MODEL_PATH = \"/kaggle/input/chess-model/pytorch/default/1/best_model.pth\"\n",
        "\n",
        "model = ChessPolicyNet().to(device)\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded on\", device)\n",
        "\n",
        "\n",
        "def select_bot_move(board: chess.Board, model, temperature=0.7):\n",
        "    x = board_to_tensor(board)\n",
        "    x = torch.tensor(x, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(x)[0].cpu().numpy()\n",
        "\n",
        "    legal_moves = list(board.legal_moves)\n",
        "    legal_indices = [\n",
        "        move.from_square * 64 + move.to_square\n",
        "        for move in legal_moves\n",
        "    ]\n",
        "\n",
        "    legal_logits = logits[legal_indices]\n",
        "\n",
        "    if temperature > 0:\n",
        "        probs = np.exp(legal_logits / temperature)\n",
        "        probs /= probs.sum()\n",
        "        idx = np.random.choice(len(legal_moves), p=probs)\n",
        "    else:\n",
        "        idx = np.argmax(legal_logits)\n",
        "\n",
        "    return legal_moves[idx]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization helpers and interactive play\n",
        "\n",
        "import chess.svg\n",
        "from IPython.display import display, HTML, SVG\n",
        "\n",
        "\n",
        "def show_boards_side_by_side(board_left, board_right, size=300,\n",
        "                             left_title=\"After Human Move\",\n",
        "                             right_title=\"After Bot Move\"):\n",
        "    svg_left = chess.svg.board(board=board_left, size=size)\n",
        "    svg_right = chess.svg.board(board=board_right, size=size)\n",
        "\n",
        "    html = f\"\"\"\n",
        "    <div style=\"display:flex; gap:30px; align-items:flex-start;\">\n",
        "        <div style=\"text-align:center;\">\n",
        "            <h4>{left_title}</h4>\n",
        "            {svg_left}\n",
        "        </div>\n",
        "        <div style=\"text-align:center;\">\n",
        "            <h4>{right_title}</h4>\n",
        "            {svg_right}\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    display(HTML(html))\n",
        "\n",
        "\n",
        "def show_board(board, size=300):\n",
        "    display(SVG(chess.svg.board(board=board, size=size)))\n",
        "\n",
        "\n",
        "board = chess.Board()\n",
        "\n",
        "\n",
        "def human_move(move_uci, temperature=0.7):\n",
        "    global board\n",
        "\n",
        "    if board.is_game_over():\n",
        "        print(\"Game over:\", board.result())\n",
        "        return\n",
        "\n",
        "    move = chess.Move.from_uci(move_uci)\n",
        "    if move not in board.legal_moves:\n",
        "        print(\"Illegal move:\", move_uci)\n",
        "        return\n",
        "\n",
        "    board.push(move)\n",
        "    print(\"Human plays:\", move_uci)\n",
        "\n",
        "    board_after_human = board.copy()\n",
        "\n",
        "    if board.is_game_over():\n",
        "        show_boards_side_by_side(board_after_human, board_after_human)\n",
        "        print(\"Game over:\", board.result())\n",
        "        return\n",
        "\n",
        "    bot_move = select_bot_move(board, model, temperature)\n",
        "    board.push(bot_move)\n",
        "    print(\"Bot plays:\", bot_move)\n",
        "\n",
        "    board_after_bot = board.copy()\n",
        "\n",
        "    show_boards_side_by_side(\n",
        "        board_after_human,\n",
        "        board_after_bot,\n",
        "        size=280,\n",
        "    )\n",
        "\n",
        "    if board.is_game_over():\n",
        "        print(\"Game over:\", board.result())\n",
        "\n",
        "\n",
        "def new_game():\n",
        "    global board\n",
        "    board = chess.Board()\n",
        "    print(\"New game started. You are White.\")\n",
        "    show_board(board)\n",
        "\n",
        "\n",
        "new_game()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: single move from a custom position\n",
        "\n",
        "def select_bot_move_temperature(board: chess.Board, model, temperature=1.0):\n",
        "    x = board_to_tensor(board)\n",
        "    x = torch.tensor(x, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(x)[0].cpu().numpy()\n",
        "\n",
        "    legal_moves = list(board.legal_moves)\n",
        "    legal_indices = [\n",
        "        move.from_square * 64 + move.to_square\n",
        "        for move in legal_moves\n",
        "    ]\n",
        "\n",
        "    legal_logits = logits[legal_indices]\n",
        "\n",
        "    if temperature > 0:\n",
        "        probs = np.exp(legal_logits / temperature)\n",
        "        probs /= probs.sum()\n",
        "        chosen_idx = np.random.choice(len(legal_indices), p=probs)\n",
        "    else:\n",
        "        chosen_idx = np.argmax(legal_logits)\n",
        "\n",
        "    return legal_moves[chosen_idx]\n",
        "\n",
        "\n",
        "board_example = chess.Board(\n",
        "    \"r1bqkbnr/pppp1ppp/2n5/4p3/2B1P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 2 3\"\n",
        ")\n",
        "move = select_bot_move_temperature(\n",
        "    board=board_example,\n",
        "    model=model,\n",
        "    temperature=0.8,\n",
        ")\n",
        "\n",
        "print(\"Predicted move:\", move)\n",
        "print(\"UCI format:\", move.uci())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top-k accuracy evaluation\n",
        "\n",
        "\n",
        "def top_k_accuracy(model, loader, k=5):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "\n",
        "            topk = logits.topk(k, dim=1).indices\n",
        "            correct += (topk == y.unsqueeze(1)).any(dim=1).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "print(\"Top-1:\", top_k_accuracy(model, test_loader, k=1))\n",
        "print(\"Top-5:\", top_k_accuracy(model, test_loader, k=5))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
